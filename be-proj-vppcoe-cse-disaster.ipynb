{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-06T08:29:35.283344Z","iopub.execute_input":"2023-02-06T08:29:35.283808Z","iopub.status.idle":"2023-02-06T08:29:35.289570Z","shell.execute_reply.started":"2023-02-06T08:29:35.283771Z","shell.execute_reply":"2023-02-06T08:29:35.288342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -lha ../input/satellite-images-of-hurricane-damage","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:29:35.295282Z","iopub.execute_input":"2023-02-06T08:29:35.296027Z","iopub.status.idle":"2023-02-06T08:29:36.428623Z","shell.execute_reply.started":"2023-02-06T08:29:35.295990Z","shell.execute_reply":"2023-02-06T08:29:36.427477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_path = '../input/satellite-images-of-hurricane-damage/'\n\ndef print_file_sizes(input_path, subset):\n    print('{}:'.format(subset))\n    print('')\n    path = input_path + subset + '/'\n    for f in os.listdir(path):\n        if not os.path.isdir(path + f):\n            print(f.ljust(30) + str(round(os.path.getsize(path + f) / 1000000, 2)) + 'MB')\n        else:\n            sizes = [os.path.getsize(path+f+'/'+x)/1000000 for x in os.listdir(path + f)]\n            print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + ' ({} files)'.format(len(sizes)))\n    print('')\n    \nprint_file_sizes(input_path, 'train_another')\nprint_file_sizes(input_path, 'validation_another')\nprint_file_sizes(input_path, 'test_another')\nprint_file_sizes(input_path, 'test')","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:29:36.430979Z","iopub.execute_input":"2023-02-06T08:29:36.432040Z","iopub.status.idle":"2023-02-06T08:30:34.446688Z","shell.execute_reply.started":"2023-02-06T08:29:36.431996Z","shell.execute_reply":"2023-02-06T08:30:34.445413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df = pd.DataFrame({'path': list(Path(input_path).glob('**/*.jp*g'))})\nimage_df['damage'] = image_df['path'].map(lambda x: x.parent.stem)\nimage_df['data_split'] = image_df['path'].map(lambda x: x.parent.parent.stem)\nimage_df['location'] = image_df['path'].map(lambda x: x.stem)\nimage_df['lon'] = image_df['location'].map(lambda x: float(x.split('_')[0]))\nimage_df['lat'] = image_df['location'].map(lambda x: float(x.split('_')[-1]))\nimage_df['path'] = image_df['path'].map(lambda x: str(x))\nimage_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:34.448191Z","iopub.execute_input":"2023-02-06T08:30:34.449315Z","iopub.status.idle":"2023-02-06T08:30:46.881514Z","shell.execute_reply.started":"2023-02-06T08:30:34.449272Z","shell.execute_reply":"2023-02-06T08:30:46.880161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n\ns = 3\nalpha = 0.25\n\n# get the train-validation-test splits\nimage_df_train = image_df[image_df['data_split']=='train_another'].copy()\nimage_df_val = image_df[image_df['data_split']=='validation_another'].copy()\nimage_df_test = image_df[image_df['data_split']=='test_another'].copy()\n\n# sort to ensure reproducible behaviour\nimage_df_train.sort_values('lat', inplace=True)\nimage_df_val.sort_values('lat', inplace=True)\nimage_df_test.sort_values('lat', inplace=True)\nimage_df_train.reset_index(drop=True,inplace=True)\nimage_df_val.reset_index(drop=True,inplace=True)\nimage_df_test.reset_index(drop=True,inplace=True)\n\nax[0].scatter(image_df_train['lon'], image_df_train['lat'], color='C0', s=s, alpha=alpha, label='train')\nax[0].scatter(image_df_val['lon'], image_df_val['lat'], color='C1', s=s, alpha=alpha, label='validation')\n\nax[0].set_title('split', fontsize=14, fontweight='bold')\nax[0].legend()\nax[0].set_xlabel('longitude')\nax[0].set_ylabel('latitude')\n\nimage_df_dmg = image_df[image_df['damage']=='damage'].copy()\nimage_df_nodmg = image_df[image_df['damage']=='no_damage'].copy()\n\nimage_df_dmg.reset_index(drop=True,inplace=True)\nimage_df_nodmg.reset_index(drop=True,inplace=True)\n\nax[1].scatter(image_df_dmg['lon'], image_df_dmg['lat'], color='C0', s=s, alpha=alpha, label='damage')\nax[1].scatter(image_df_nodmg['lon'], image_df_nodmg['lat'], color='C1', s=s, alpha=alpha, label='no damage')\n\nax[1].set_title('label', fontsize=14, fontweight='bold')\nax[1].legend()\nax[1].set_xlabel('longitude')\nax[1].set_ylabel('latitude')\n\nplt.show(fig)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:46.885185Z","iopub.execute_input":"2023-02-06T08:30:46.885733Z","iopub.status.idle":"2023-02-06T08:30:47.742630Z","shell.execute_reply.started":"2023-02-06T08:30:46.885681Z","shell.execute_reply":"2023-02-06T08:30:47.740895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,6), sharex=True, sharey=True)\n\ns = 20\nalpha = 0.25\n\nax[0].scatter(image_df_dmg['lon'], image_df_dmg['lat'], color='C0', s=s, alpha=alpha, label='damage')\nax[0].set_title('damage', fontsize=14, fontweight='bold')\n\nax[1].scatter(image_df_dmg['lon'], image_df_dmg['lat'], color='k', s=s, alpha=alpha, label='damage')\nax[1].scatter(image_df_nodmg['lon'], image_df_nodmg['lat'], color='k', s=s, alpha=alpha, label='no damage')\nax[1].set_title('all images', fontsize=14, fontweight='bold')\n\nax[2].scatter(image_df_nodmg['lon'], image_df_nodmg['lat'], color='C1', s=s, alpha=alpha, label='no damage')\nax[2].set_title('no damage', fontsize=14, fontweight='bold')\n\nax[0].set_ylabel('latitude')\nax[0].set_xlabel('longitude')\nax[1].set_xlabel('longitude')\nax[2].set_xlabel('longitude')\n\nax[0].set_xlim(-95.3,-95)\nax[0].set_ylim(29.7,30.2)\n\nplt.show(fig)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:47.744279Z","iopub.execute_input":"2023-02-06T08:30:47.744745Z","iopub.status.idle":"2023-02-06T08:30:48.256167Z","shell.execute_reply.started":"2023-02-06T08:30:47.744702Z","shell.execute_reply":"2023-02-06T08:30:48.254831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\n# read it in unchanged, to make sure we aren't losing any information\nimg = cv2.imread(image_df['path'][0], cv2.IMREAD_UNCHANGED)\nnp.shape(img)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:48.259297Z","iopub.execute_input":"2023-02-06T08:30:48.259676Z","iopub.status.idle":"2023-02-06T08:30:48.534571Z","shell.execute_reply.started":"2023-02-06T08:30:48.259642Z","shell.execute_reply":"2023-02-06T08:30:48.533349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(img[0,0,0])","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:48.536411Z","iopub.execute_input":"2023-02-06T08:30:48.536884Z","iopub.status.idle":"2023-02-06T08:30:48.545129Z","shell.execute_reply.started":"2023-02-06T08:30:48.536837Z","shell.execute_reply":"2023-02-06T08:30:48.543909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.min(img[:,:,:])","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:48.547043Z","iopub.execute_input":"2023-02-06T08:30:48.547439Z","iopub.status.idle":"2023-02-06T08:30:48.559194Z","shell.execute_reply.started":"2023-02-06T08:30:48.547406Z","shell.execute_reply":"2023-02-06T08:30:48.558113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.max(img[:,:,:])","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:48.560909Z","iopub.execute_input":"2023-02-06T08:30:48.561237Z","iopub.status.idle":"2023-02-06T08:30:48.569820Z","shell.execute_reply.started":"2023-02-06T08:30:48.561208Z","shell.execute_reply":"2023-02-06T08:30:48.568757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=10, sharex=True, sharey=True, figsize=(20,10))\n\nax = ax.flatten()\n\nfor i in range(20):\n    img = cv2.imread(image_df_dmg['path'][i], cv2.IMREAD_UNCHANGED)\n    ax[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i].set_title('damage')\n    \nfor i in range(20,40):\n    img = cv2.imread(image_df_nodmg['path'][i], cv2.IMREAD_UNCHANGED)\n    ax[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i].set_title('no damage')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:48.574281Z","iopub.execute_input":"2023-02-06T08:30:48.574712Z","iopub.status.idle":"2023-02-06T08:30:53.302828Z","shell.execute_reply.started":"2023-02-06T08:30:48.574676Z","shell.execute_reply":"2023-02-06T08:30:53.301516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=3, sharex=True, sharey=True, figsize=(15,20))\n\nax = ax.flatten()\n\nselected_dmg = np.array([0,1,2,3,4,5])*100\nselected_nodmg = np.array([0,1,2,3,4,5])*99\n\nfor i in range(6):\n    img = cv2.imread(image_df_dmg['path'][selected_dmg[i]], cv2.IMREAD_UNCHANGED)\n    ax[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    #ax[i].set_title('damage')\n    \nfor i in range(6):\n    img = cv2.imread(image_df_nodmg['path'][selected_nodmg[i]], cv2.IMREAD_UNCHANGED)\n    ax[i+6].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    #ax[i+6].set_title('no damage')\n    \nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:53.304537Z","iopub.execute_input":"2023-02-06T08:30:53.304930Z","iopub.status.idle":"2023-02-06T08:30:56.166631Z","shell.execute_reply.started":"2023-02-06T08:30:53.304894Z","shell.execute_reply":"2023-02-06T08:30:56.164922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jpg_channels = ['blue','green','red']\njpg_channel_colors = ['b','g','r']\n\nfig, ax = plt.subplots(figsize=(15,6))\n\nfor i in range(len(jpg_channels)):\n    ax.hist(img[:,:,i].flatten(), bins=np.arange(256),\n            label=jpg_channels[i], color=jpg_channel_colors[i], alpha=0.5)\n    ax.legend()\n    \nax.set_xlim(0,255)\n    \nplt.show(fig)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:56.168262Z","iopub.execute_input":"2023-02-06T08:30:56.168681Z","iopub.status.idle":"2023-02-06T08:30:58.324631Z","shell.execute_reply.started":"2023-02-06T08:30:56.168641Z","shell.execute_reply":"2023-02-06T08:30:58.323149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:30:58.326181Z","iopub.execute_input":"2023-02-06T08:30:58.326753Z","iopub.status.idle":"2023-02-06T08:31:04.676959Z","shell.execute_reply.started":"2023-02-06T08:30:58.326715Z","shell.execute_reply":"2023-02-06T08:31:04.675692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths\ntrain_path = image_df_train['path'].copy().values\nval_path = image_df_val['path'].copy().values\ntest_path = image_df_test['path'].copy().values\n\n# labels\ntrain_labels = np.zeros(len(image_df_train), dtype=np.int8)\ntrain_labels[image_df_train['damage'].values=='damage'] = 1\n\nval_labels = np.zeros(len(image_df_val), dtype=np.int8)\nval_labels[image_df_val['damage'].values=='damage'] = 1\n\ntest_labels = np.zeros(len(image_df_test), dtype=np.int8)\ntest_labels[image_df_test['damage'].values=='damage'] = 1","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:31:04.679050Z","iopub.execute_input":"2023-02-06T08:31:04.679990Z","iopub.status.idle":"2023-02-06T08:31:04.691195Z","shell.execute_reply.started":"2023-02-06T08:31:04.679940Z","shell.execute_reply":"2023-02-06T08:31:04.689709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.data.Dataset.from_tensor_slices((train_path, train_labels))\nval_ds = tf.data.Dataset.from_tensor_slices((val_path, val_labels))\ntest_ds = tf.data.Dataset.from_tensor_slices((test_path, test_labels))\n\n# note that the `numpy()` function is required to grab the actual values from the Dataset\nfor path, label in train_ds.take(5):\n    print(\"path  : \", path.numpy().decode('utf-8'))\n    print(\"label : \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:31:04.692831Z","iopub.execute_input":"2023-02-06T08:31:04.693191Z","iopub.status.idle":"2023-02-06T08:31:04.810322Z","shell.execute_reply.started":"2023-02-06T08:31:04.693158Z","shell.execute_reply":"2023-02-06T08:31:04.808959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this function wraps `cv2.imread` - we treat it as a 'standalone' function, and therefore can use\n# eager execution (i.e. the use of `numpy()`) to get a string of the path.\n# note that no tensorflow functions are used here\ndef cv2_imread(path, label):\n    # read in the image, getting the string of the path via eager execution\n    img = cv2.imread(path.numpy().decode('utf-8'), cv2.IMREAD_UNCHANGED)\n    # change from BGR to RGB\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img, label\n\n# this function assumes that the image has been read in, and does some transformations on it\n# note that only tensorflow functions are used here\ndef tf_cleanup(img, label):\n    # convert to Tensor\n    img = tf.convert_to_tensor(img)\n    # unclear why, but the jpeg is read in as uint16 - convert to uint8\n    img = tf.dtypes.cast(img, tf.uint8)\n    # set the shape of the Tensor\n    img.set_shape((128, 128, 3))\n    # convert to float32, scaling from uint8 (0-255) to float32 (0-1)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # resize the image\n    img = tf.image.resize(img, [128, 128])\n    # convert the labels into a Tensor and set the shape\n    label = tf.convert_to_tensor(label)\n    label.set_shape(())\n    return img, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# map the cv2 wrapper function using `tf.py_function`\ntrain_ds = train_ds.map(lambda path, label: tuple(tf.py_function(cv2_imread, [path, label], [tf.uint16, label.dtype])),\n                        num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(lambda path, label: tuple(tf.py_function(cv2_imread, [path, label], [tf.uint16, label.dtype])),\n                    num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(lambda path, label: tuple(tf.py_function(cv2_imread, [path, label], [tf.uint16, label.dtype])),\n                      num_parallel_calls=AUTOTUNE)\n\n# map the TensorFlow transformation function - no need to wrap\ntrain_ds = train_ds.map(tf_cleanup, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(tf_cleanup, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(tf_cleanup, num_parallel_calls=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:31:04.812106Z","iopub.execute_input":"2023-02-06T08:31:04.813290Z","iopub.status.idle":"2023-02-06T08:31:05.084535Z","shell.execute_reply.started":"2023-02-06T08:31:04.813240Z","shell.execute_reply":"2023-02-06T08:31:05.082891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rotate_augmentation(img, label):\n    # rotate 0, 90, 180, or 270 degrees with 25% probability for each\n    img = tf.image.rot90(img, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32, seed=1111))\n    return img, label\n\ndef flip_augmentation(img, label):\n    # flip with 50% probability for left-right and up-down\n    img = tf.image.random_flip_left_right(img, seed=2222)\n    img = tf.image.random_flip_up_down(img, seed=3333)\n    return img, label\n\n# map the augmentations, creating a new Dataset\naugmented_train_ds = train_ds.map(rotate_augmentation, num_parallel_calls=AUTOTUNE)\naugmented_train_ds = augmented_train_ds.map(flip_augmentation, num_parallel_calls=AUTOTUNE)\n\naugmented_val_ds = val_ds.map(rotate_augmentation, num_parallel_calls=AUTOTUNE)\naugmented_val_ds = augmented_val_ds.map(flip_augmentation, num_parallel_calls=AUTOTUNE)\n\n# concatenate the augmented and original datasets\ntrain_ds = train_ds.concatenate(augmented_train_ds)\nval_ds = val_ds.concatenate(augmented_val_ds)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:31:05.086450Z","iopub.execute_input":"2023-02-06T08:31:05.087748Z","iopub.status.idle":"2023-02-06T08:31:05.368373Z","shell.execute_reply.started":"2023-02-06T08:31:05.087700Z","shell.execute_reply":"2023-02-06T08:31:05.367453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# double the number of samples in the training and validation splits, due to our augmentation procedure\nn_train = len(train_labels)*2\nn_val = len(val_labels)*2\nn_test = len(test_labels)\n\n# shuffle over the entire dataset, seeding the shuffling for reproducible results\ntrain_ds = train_ds.shuffle(n_train, seed=208, reshuffle_each_iteration=True)\nval_ds = val_ds.shuffle(n_val, seed=208, reshuffle_each_iteration=True)\ntest_ds = test_ds.shuffle(n_test, seed=208, reshuffle_each_iteration=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:31:05.369666Z","iopub.execute_input":"2023-02-06T08:31:05.370223Z","iopub.status.idle":"2023-02-06T08:31:05.419439Z","shell.execute_reply.started":"2023-02-06T08:31:05.370181Z","shell.execute_reply":"2023-02-06T08:31:05.417825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_train_check = 0\nfor element in train_ds:\n    n_train_check = n_train_check + 1\nprint(n_train_check)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:31:05.421003Z","iopub.execute_input":"2023-02-06T08:31:05.421410Z","iopub.status.idle":"2023-02-06T08:31:46.411614Z","shell.execute_reply.started":"2023-02-06T08:31:05.421352Z","shell.execute_reply":"2023-02-06T08:31:46.410123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_val_check = 0\nfor element in val_ds:\n    n_val_check = n_val_check + 1\nprint(n_val_check)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:31:46.413525Z","iopub.execute_input":"2023-02-06T08:31:46.413915Z","iopub.status.idle":"2023-02-06T08:31:51.549959Z","shell.execute_reply.started":"2023-02-06T08:31:46.413881Z","shell.execute_reply":"2023-02-06T08:31:51.548774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_test_check = 0\nfor element in test_ds:\n    n_test_check = n_test_check + 1\nprint(n_test_check)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:31:51.551451Z","iopub.execute_input":"2023-02-06T08:31:51.551799Z","iopub.status.idle":"2023-02-06T08:32:04.543177Z","shell.execute_reply.started":"2023-02-06T08:31:51.551766Z","shell.execute_reply":"2023-02-06T08:32:04.541799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check that the image was read in correctly\nfor image, label in train_ds.take(1):\n    print(\"image shape : \", image.numpy().shape)\n    print(\"label       : \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:32:04.544665Z","iopub.execute_input":"2023-02-06T08:32:04.545129Z","iopub.status.idle":"2023-02-06T08:32:22.612372Z","shell.execute_reply.started":"2023-02-06T08:32:04.545094Z","shell.execute_reply":"2023-02-06T08:32:22.611132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=10, sharex=True, sharey=True, figsize=(20,10))\n\ni = 0\n\nfor image, label in train_ds.take(10):\n    ax[0,i].imshow(image[:,:,0])\n    ax[0,i].set_title('{} - {}'.format(label.numpy(), 'R'))\n    ax[1,i].imshow(image[:,:,1])\n    ax[1,i].set_title('{} - {}'.format(label.numpy(), 'G'))\n    ax[2,i].imshow(image[:,:,2])\n    ax[2,i].set_title('{} - {}'.format(label.numpy(), 'B'))\n    ax[3,i].imshow(image)\n    ax[3,i].set_title('{} - {}'.format(label.numpy(), 'RGB'))\n    \n    i = i+1","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:32:22.614727Z","iopub.execute_input":"2023-02-06T08:32:22.615508Z","iopub.status.idle":"2023-02-06T08:32:44.927288Z","shell.execute_reply.started":"2023-02-06T08:32:22.615456Z","shell.execute_reply":"2023-02-06T08:32:44.926229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=3, sharex=True, sharey=True, figsize=(20,15))\n\nax[0,0].set_xlim(0,1)\n\ni = 0\n\nfor image, label in train_ds.take(3):\n    ax[i,0].hist(image[:,:,0].numpy().flatten())\n    ax[i,0].set_title('{} - {}'.format(label.numpy(), 'R'))\n    ax[i,1].hist(image[:,:,1].numpy().flatten())\n    ax[i,1].set_title('{} - {}'.format(label.numpy(), 'G'))\n    ax[i,2].hist(image[:,:,2].numpy().flatten())\n    ax[i,2].set_title('{} - {}'.format(label.numpy(), 'B'))\n    \n    i = i+1","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:32:44.928954Z","iopub.execute_input":"2023-02-06T08:32:44.929551Z","iopub.status.idle":"2023-02-06T08:33:04.038495Z","shell.execute_reply.started":"2023-02-06T08:32:44.929514Z","shell.execute_reply":"2023-02-06T08:33:04.036462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\n\ntrain_batches_ds = train_ds.batch(BATCH_SIZE)\nval_batches_ds = val_ds.batch(BATCH_SIZE)\ntest_batches_ds = test_ds.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:04.040627Z","iopub.execute_input":"2023-02-06T08:33:04.041043Z","iopub.status.idle":"2023-02-06T08:33:04.052257Z","shell.execute_reply.started":"2023-02-06T08:33:04.040987Z","shell.execute_reply":"2023-02-06T08:33:04.050943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_batch, label_batch in train_batches_ds.take(1):\n    print(image_batch.shape)\n    print(label_batch.numpy())","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:04.054196Z","iopub.execute_input":"2023-02-06T08:33:04.055859Z","iopub.status.idle":"2023-02-06T08:33:24.572281Z","shell.execute_reply.started":"2023-02-06T08:33:04.055799Z","shell.execute_reply":"2023-02-06T08:33:24.571157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SHAPE = (128, 128, 3)\n\n# create the base model from the pre-trained model VGG16\n# note that, if using a Kaggle server, internet has to be turned on\npretrained_model = tf.keras.applications.vgg16.VGG16(input_shape=IMG_SHAPE,\n                                                     include_top=False,\n                                                     weights='imagenet')\n\n# freeze the convolutional base\npretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:24.574201Z","iopub.execute_input":"2023-02-06T08:33:24.575047Z","iopub.status.idle":"2023-02-06T08:33:28.478217Z","shell.execute_reply.started":"2023-02-06T08:33:24.575006Z","shell.execute_reply":"2023-02-06T08:33:28.476819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_batch = pretrained_model(image_batch)\nprint(feature_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:28.484690Z","iopub.execute_input":"2023-02-06T08:33:28.485085Z","iopub.status.idle":"2023-02-06T08:33:31.252457Z","shell.execute_reply.started":"2023-02-06T08:33:28.485052Z","shell.execute_reply":"2023-02-06T08:33:31.251472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:31.253346Z","iopub.execute_input":"2023-02-06T08:33:31.253678Z","iopub.status.idle":"2023-02-06T08:33:31.267154Z","shell.execute_reply.started":"2023-02-06T08:33:31.253648Z","shell.execute_reply":"2023-02-06T08:33:31.266204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:31.269324Z","iopub.execute_input":"2023-02-06T08:33:31.270261Z","iopub.status.idle":"2023-02-06T08:33:31.284753Z","shell.execute_reply.started":"2023-02-06T08:33:31.270218Z","shell.execute_reply":"2023-02-06T08:33:31.283567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set the initializers with a seed for reproducible behaviour\nprediction_layer = tf.keras.layers.Dense(1,\n                                         kernel_initializer=tf.keras.initializers.GlorotUniform(seed=1992),\n                                         bias_initializer=tf.keras.initializers.GlorotUniform(seed=1992))\n\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:31.286623Z","iopub.execute_input":"2023-02-06T08:33:31.287319Z","iopub.status.idle":"2023-02-06T08:33:31.333320Z","shell.execute_reply.started":"2023-02-06T08:33:31.287282Z","shell.execute_reply":"2023-02-06T08:33:31.332458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([pretrained_model,\n                             global_average_layer,\n                             prediction_layer])","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:31.334922Z","iopub.execute_input":"2023-02-06T08:33:31.336197Z","iopub.status.idle":"2023-02-06T08:33:31.411939Z","shell.execute_reply.started":"2023-02-06T08:33:31.336141Z","shell.execute_reply":"2023-02-06T08:33:31.410323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:31.413872Z","iopub.execute_input":"2023-02-06T08:33:31.414363Z","iopub.status.idle":"2023-02-06T08:33:31.435055Z","shell.execute_reply.started":"2023-02-06T08:33:31.414316Z","shell.execute_reply":"2023-02-06T08:33:31.433533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:31.436483Z","iopub.execute_input":"2023-02-06T08:33:31.436853Z","iopub.status.idle":"2023-02-06T08:33:31.444104Z","shell.execute_reply.started":"2023-02-06T08:33:31.436817Z","shell.execute_reply":"2023-02-06T08:33:31.443130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initial_epochs = 1\nsteps_per_epoch = n_train//BATCH_SIZE\nvalidation_steps = 20\n\nloss0, accuracy0 = model.evaluate(val_batches_ds, steps=validation_steps)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:33:31.445105Z","iopub.execute_input":"2023-02-06T08:33:31.445475Z","iopub.status.idle":"2023-02-06T08:34:29.006867Z","shell.execute_reply.started":"2023-02-06T08:33:31.445440Z","shell.execute_reply":"2023-02-06T08:34:29.005510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_batches_ds,\n                    epochs=initial_epochs,\n                    validation_data=val_batches_ds,\n                    validation_steps=validation_steps)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T08:34:29.008678Z","iopub.execute_input":"2023-02-06T08:34:29.009028Z","iopub.status.idle":"2023-02-06T09:03:33.274353Z","shell.execute_reply.started":"2023-02-06T08:34:29.008996Z","shell.execute_reply":"2023-02-06T09:03:33.273287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nfig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10,8), sharex=True)\n\nx_plot = np.arange(1, initial_epochs+1)\n\nax[0].plot(x_plot, acc, '+-', label='training')\nax[0].plot(x_plot, val_acc, '+-', label='validation')\nax[0].legend()\nax[0].set_ylabel('accuracy')\nax[0].set_ylim(0.5, 1)\nax[0].grid(ls='--', c='C7')\nax[0].set_title('accuracy')\n\nax[1].plot(x_plot, loss, '+-', label='training')\nax[1].plot(x_plot, val_loss, '+-', label='validation')\nax[1].legend()\nax[1].set_ylabel('cross entropy')\nax[1].set_ylim(0, 1)\nax[1].grid(ls='--', c='C7')\nax[1].set_title('loss')\nax[1].set_xlabel('epoch')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:03:33.276421Z","iopub.execute_input":"2023-02-06T09:03:33.277101Z","iopub.status.idle":"2023-02-06T09:03:33.647353Z","shell.execute_reply.started":"2023-02-06T09:03:33.277060Z","shell.execute_reply":"2023-02-06T09:03:33.646005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unfreeze the layers\npretrained_model.trainable = True\n\n# let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the pre-trained model: \", len(pretrained_model.layers))","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:03:33.648981Z","iopub.execute_input":"2023-02-06T09:03:33.649631Z","iopub.status.idle":"2023-02-06T09:03:33.657550Z","shell.execute_reply.started":"2023-02-06T09:03:33.649591Z","shell.execute_reply":"2023-02-06T09:03:33.656296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fine-tune from this layer onwards\nfine_tune_at = 15\n\n# freeze all the layers before the `fine_tune_at` layer\nfor layer in pretrained_model.layers[:fine_tune_at]:\n  layer.trainable =  False","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:03:33.658701Z","iopub.execute_input":"2023-02-06T09:03:33.659086Z","iopub.status.idle":"2023-02-06T09:03:33.675367Z","shell.execute_reply.started":"2023-02-06T09:03:33.659049Z","shell.execute_reply":"2023-02-06T09:03:33.674228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate/75),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:03:33.676366Z","iopub.execute_input":"2023-02-06T09:03:33.676730Z","iopub.status.idle":"2023-02-06T09:03:33.700195Z","shell.execute_reply.started":"2023-02-06T09:03:33.676696Z","shell.execute_reply":"2023-02-06T09:03:33.698917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(model.trainable_variables)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:03:33.701370Z","iopub.execute_input":"2023-02-06T09:03:33.701727Z","iopub.status.idle":"2023-02-06T09:03:33.711714Z","shell.execute_reply.started":"2023-02-06T09:03:33.701694Z","shell.execute_reply":"2023-02-06T09:03:33.710506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fine_tune_epochs = 1\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model.fit(train_batches_ds,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1]+1,\n                         validation_data=val_batches_ds,\n                         validation_steps=validation_steps)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:03:33.713555Z","iopub.execute_input":"2023-02-06T09:03:33.714290Z","iopub.status.idle":"2023-02-06T09:37:46.618198Z","shell.execute_reply.started":"2023-02-06T09:03:33.714239Z","shell.execute_reply":"2023-02-06T09:37:46.617200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']\n\nfig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10,8), sharex=True)\n\nx_plot = np.arange(1, total_epochs+1)\n\nax[0].plot(x_plot, acc, '+-', label='training')\nax[0].plot(x_plot, val_acc, '+-', label='validation')\nax[0].legend()\nax[0].set_ylabel('accuracy')\nax[0].set_ylim(0.5, 1)\nax[0].grid(ls='--', c='C7')\nax[0].set_title('accuracy')\nax[0].axvline(initial_epochs, c='C7', ls='--')\n\nax[1].plot(x_plot, loss, '+-', label='training')\nax[1].plot(x_plot, val_loss, '+-', label='validation')\nax[1].legend()\nax[1].set_ylabel('cross entropy')\nax[1].set_ylim(0, 1)\nax[1].grid(ls='--', c='C7')\nax[1].set_title('loss')\nax[1].set_xlabel('epoch')\nax[1].axvline(initial_epochs, c='C7', ls='--')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:37:46.619915Z","iopub.execute_input":"2023-02-06T09:37:46.620815Z","iopub.status.idle":"2023-02-06T09:37:47.024871Z","shell.execute_reply.started":"2023-02-06T09:37:46.620775Z","shell.execute_reply":"2023-02-06T09:37:47.023695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_loss, val_accuracy = model.evaluate(val_batches_ds)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:37:47.026074Z","iopub.execute_input":"2023-02-06T09:37:47.026432Z","iopub.status.idle":"2023-02-06T09:43:23.891852Z","shell.execute_reply.started":"2023-02-06T09:37:47.026399Z","shell.execute_reply":"2023-02-06T09:43:23.890707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_batches_ds)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:43:23.893618Z","iopub.execute_input":"2023-02-06T09:43:23.894044Z","iopub.status.idle":"2023-02-06T09:56:03.296844Z","shell.execute_reply.started":"2023-02-06T09:43:23.893994Z","shell.execute_reply":"2023-02-06T09:56:03.295724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract images and labels from the batches, and store predictions\neval_labels = np.array([])\neval_predictions = np.array([])\nfirst = True\nfor images, labels in test_batches_ds.take(-1): #take all the batches\n    if first:\n        eval_images = images.numpy()\n        first = False\n    else:\n        eval_images = np.concatenate((eval_images, images.numpy()), axis=0)\n    eval_labels = np.append(eval_labels, labels.numpy())\n    eval_predictions = np.append(eval_predictions, model.predict_on_batch(images))\n    \n# convert predictions from logit to binary\neval_predictions[eval_predictions>=0] = 1\neval_predictions[eval_predictions<0] = 0\n\n# change dtype to int\neval_predictions = eval_predictions.astype(int)\neval_labels = eval_labels.astype(int)\n\n# check that we extracted the images and the labels correctly\nprint(\"eval_images      : \", eval_images.shape)\nprint(\"eval_labels      : \", eval_labels.shape)\nprint(\"eval_predictions : \", eval_predictions.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:56:03.298474Z","iopub.execute_input":"2023-02-06T09:56:03.298875Z","iopub.status.idle":"2023-02-06T10:10:22.157830Z","shell.execute_reply.started":"2023-02-06T09:56:03.298839Z","shell.execute_reply":"2023-02-06T10:10:22.156605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_mtx = confusion_matrix(eval_labels, eval_predictions)\nconfusion_mtx","metadata":{"execution":{"iopub.status.busy":"2023-02-06T10:10:22.159287Z","iopub.execute_input":"2023-02-06T10:10:22.159693Z","iopub.status.idle":"2023-02-06T10:10:22.520471Z","shell.execute_reply.started":"2023-02-06T10:10:22.159657Z","shell.execute_reply":"2023-02-06T10:10:22.519018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nTN = confusion_mtx[0,0]\nFN = confusion_mtx[1,0]\nTP = confusion_mtx[1,1]\nFP = confusion_mtx[0,1]\nF1 = f1_score(eval_labels, eval_predictions)\n\nprint('accuracy = {:.4f}'.format((TP+TN)/np.sum(confusion_mtx)))\nprint('positive recall = {:.4f}'.format(TP/(TP+FN)))\nprint('negative recall = {:.4f}'.format(TN/(TN+FP)))\nprint('positive precision = {:.4f}'.format(TP/(TP+FP)))\nprint('negative precision = {:.4f}'.format(TN/(TN+FN)))","metadata":{"execution":{"iopub.status.busy":"2023-02-06T10:10:22.521932Z","iopub.execute_input":"2023-02-06T10:10:22.522369Z","iopub.status.idle":"2023-02-06T10:10:22.765430Z","shell.execute_reply.started":"2023-02-06T10:10:22.522334Z","shell.execute_reply":"2023-02-06T10:10:22.763492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b_TP = TP/8\nb_FN = FN/8\n\nprint('accuracy = {:.4f}'.format((b_TP+TN)/np.sum(2000)))\nprint('positive recall = {:.4f}'.format(b_TP/(b_TP+b_FN)))\nprint('negative recall = {:.4f}'.format(TN/(TN+FP)))\nprint('positive precision = {:.4f}'.format(b_TP/(b_TP+FP)))\nprint('negative precision = {:.4f}'.format(TN/(TN+b_FN)))","metadata":{"execution":{"iopub.status.busy":"2023-02-06T10:10:22.767528Z","iopub.execute_input":"2023-02-06T10:10:22.767905Z","iopub.status.idle":"2023-02-06T10:10:22.776675Z","shell.execute_reply.started":"2023-02-06T10:10:22.767872Z","shell.execute_reply":"2023-02-06T10:10:22.774997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FP_eval_images = eval_images[(eval_labels==0)&(eval_predictions==1)]\nFN_eval_images = eval_images[(eval_labels==1)&(eval_predictions==0)]\n\nselected_FP = np.arange(10, dtype=int)*2\nselected_FN = np.arange(10, dtype=int)*2\n\nfig, ax = plt.subplots(nrows=4, ncols=5, sharex=True, sharey=True, figsize=(20,16))\n\nax = ax.flatten()\n\nfor i in range(10):\n    ax[i].imshow(FP_eval_images[selected_FP[i]])\n    \nfor i in range(10):\n    ax[i+10].imshow(FN_eval_images[selected_FN[i]])\n    \nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T10:10:22.778087Z","iopub.execute_input":"2023-02-06T10:10:22.778464Z","iopub.status.idle":"2023-02-06T10:10:26.429870Z","shell.execute_reply.started":"2023-02-06T10:10:22.778425Z","shell.execute_reply":"2023-02-06T10:10:26.427997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}